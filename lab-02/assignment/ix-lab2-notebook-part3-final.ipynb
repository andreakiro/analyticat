{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *H*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Antoine Basseto*\n",
    "* *Andrea Pinto*\n",
    "* *Jérémy Baffou*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import epidemics_helper\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import part3_functions as part3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the exercices let's load our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/nyc_augmented_network.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_list = list(map(lambda d : (d['id'], {'coordinates' : d['coordinates']}),data[\"nodes\"]))\n",
    "edges_list = list(map(lambda d : (d['source'],d['target']), data[\"links\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes_list)\n",
    "G.add_edges_from(edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part3.draw_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 Epidemics\n",
    "\n",
    "#### Exercise 2.9: Simulate an epidemic outbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIR = epidemics_helper.SimulationSIR(G, beta=10.0, gamma=0.1)\n",
    "SIR.launch_epidemic(source=23654, max_time=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps_status, nodes_status = part3.nodes_status_over_time(SIR, 100, [1,3,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part3.plot_population_status(nodes_status,percentage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part3.epidemic_markers(nodes_status,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(time_stamps_status.values()), figsize=(400,500))\n",
    "fig.suptitle('Epidemic evolution of the network')\n",
    "i = 0\n",
    "for stamps, status in time_stamps_status.items():\n",
    "    axs[i].set_title(\"At day \"+ str(stamps), fontsize=300)\n",
    "    part3.draw_graph(G,nodes_status=status,ax=axs[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3.1 Stop the apocalypse!\n",
    "\n",
    "#### Exercise 2.10: Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part3.strategy_1_simulation(nodes_list,edges_list, sim_nb=2, draw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really efficient as the curves are really similar to the initial case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part3.strategy_1_simulation(nodes_list,edges_list,budget=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.11: Strategy 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to implement a strategy to maintain the epidemy under control. We thought about three of them:\n",
    "\n",
    "- Reduce the \"centrality\" of the graph\n",
    "- Isolate high degree node\n",
    "- Partition the graph in communities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High betweenness method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this strategy is that if we cut the edges with the highest edge-betweenness (i.e. which are most present in shortest paths in the graph). Then it would take more time to reach any node and thus letting the time for the node to recover before containing a huge number of neighbours. For this we used the edge_betweenness_centrality function of the library networkx. It computes for every pair of nodes the shortest path between them using the Disjktra algorithm and then for each edges, compute the percentage of shortest paths that contain it. This is really computationnal costly (we used a good portion of the cluster for around 1 hour, so it may not be the first choice. Further more it produces better result that the random strategy but not outstanding ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_centered_edges = part3.extract_max_centered_edges() #have been computed using the cluster and the function https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.edge_betweenness_centrality.html#networkx.algorithms.centrality.edge_betweenness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can visualize the edges with a high betweenness, which contains many bridges which makes sense because they are needed to connect the graph. This is a good thing to cut them because it allows us to cut the graph in several connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_high_centrality = nx.nx.Graph()\n",
    "Graph_high_centrality.add_nodes_from(nodes_list)\n",
    "Graph_high_centrality.add_edges_from(max_centered_edges[:2500])\n",
    "part3.draw_graph(Graph_high_centrality,title=\"View of high centrality edges\",edge_width=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the results of multiple simulation using our strategy of high betweenness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part3.strategy_2_simulation(nodes_list, edges_list, max_centered_edges, sim_nb=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaccination method (high degree node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible strategies (and more realistic one) is the vaccination. If you want to slow down the epidemy, the main target of the vaccination should be the people with a lot of contacts, i.e. high degree node (we suppose here that the vaccination avoid also to contaminate other people). This is not a really good idea in our situation as the cost to get rid of a high degree node is really high and thus we will spend a lot of edges on only a really small fraction of our graph and thus we find ourself in a position similar to the random case (maybe worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part3.strategy_3_simulation(nodes_list, edges_list, budget=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can effectively see that it is really similar to the random case anmd thus it is a bad strategy (but irl it is a great one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind the last strategy is to separate the graph into strongly connected community and to isolate these communities from the rest of the network. Like this, an epidemy that would start in a community cannot extend to the rest of the network, preserving the vast majority of the population. We implemented it by using the Clauset-Newman-Moore greedy modularity maximization, present in the function greedy_modularity_communities of the library networkx (https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html). Once we have our communities we use method from the boudaries section of networkx to find the edges between every communities. Then we cut them. You can see a representation of the different communities and the edges between them. This method is computationally efficient and provide excellent result, this is the one we should use to fight the epidemy.\n",
    "\n",
    "Note that we cut at max ~750 edges because this is the number of boudary edges. So incrementing the budget over 750 won't result in any changes. To optimize even more this strategy we could implement a reccurent function that works on the communities of the initial graph to split them into sub-communities, etc. We prefered exploring various strategy rather than optimizing even more this strategy that reaches already 97% of susceptible at day 30 in average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nx.algorithms.community.greedy_modularity_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part3.draw_communities(G, communities, boundaries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part3.strategy_4_simulation(nodes_list,edges_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost/Effectiveness comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a clearer view of the real \"value\" of our strategy we provide a small graph of their cost-effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = []\n",
    "vaccination = []\n",
    "betweenness = []\n",
    "community = []\n",
    "strategies = [\"random\",\"vaccination\",\"betweenness\",\"community\"]\n",
    "budgets = [100,200,300,400,500,600,700,800,900,1000,1500,2000,2500,5000,7500,10000]\n",
    "for b in budgets:\n",
    "    random.append(part3.compute_mean_susceptible(nodes_list, edges_list, b, \"random\"))\n",
    "    vaccination.append(part3.compute_mean_susceptible(nodes_list, edges_list, b, \"vaccination\"))\n",
    "    betweenness.append(part3.compute_mean_susceptible(nodes_list, edges_list, b, \"betweenness\"))\n",
    "    community.append(part3.compute_mean_susceptible(nodes_list, edges_list, b, \"community\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Comparison of cost/effectiveness for different strategies\") \n",
    "ax.set_xlabel(\"budget\")\n",
    "ax.set_ylabel(\"% of Susceptible\")\n",
    "ax.plot(budgets, random, label=\"Random\")\n",
    "ax.plot(budgets, vaccination, label=\"Vaccination\")\n",
    "ax.plot(budgets, betweenness, label=\"Betweenness\")\n",
    "ax.plot(budgets, community, label=\"Community\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the community strategy is growing exponentially reaching quickly around 97% of Susceptible. The betweenness one is slightly better than linear, but if we compare to its computationnal cost, it has a really bad cost-effectiveness. The vaccination and random strategy are sub-linear and thus pretty inneficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
