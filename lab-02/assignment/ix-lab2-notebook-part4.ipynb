{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *H*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *BAFFOU Jérémy*\n",
    "* *BASSETO Antoine*\n",
    "* *PINTO Andrea*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_directed_graph(filename):\n",
    "    \"\"\" Parse the adjacency list into a graph\n",
    "        in the form of a dictionnary.\n",
    "        \n",
    "        :param filename: name of the file containing the adjacency list\n",
    "        \n",
    "        :return: graph in the form of a dictionnary with an array of\n",
    "        adjacent nodes as the value asociated to each key\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"../data/\" + filename) as f:\n",
    "        content = f.read().splitlines()\n",
    "    \n",
    "    graph = {}\n",
    "    for line in content:\n",
    "        c = list(map(int, line.split()))\n",
    "        graph[int(c[0])] = c[1:]\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank_naive(graph, nb_iterations):\n",
    "    \"\"\" Naive implementation of the page rank algorithm,\n",
    "        not doing anything in particular to counteract dangling nodes\n",
    "        or unconnected components in the graph.\n",
    "        \n",
    "        :param graph: graph to explore, in the form of a dictionnary \n",
    "        with an array of adjacent nodes as the value asociated to each key\n",
    "        :param nb_iterations: the number of iterations the random walk is\n",
    "        going to try to take to explore the graph\n",
    "        \n",
    "        :return: the score associated to each node, normalised, in the form of an array\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = np.zeros(len(graph))\n",
    "    current = random.choice(list(graph))\n",
    "    scores[current] += 1\n",
    "    \n",
    "    for i in range(nb_iterations):\n",
    "        \n",
    "        # If the current node is a dangling one, we can just return the current result as nothing else can be done\n",
    "        if not graph[current]:\n",
    "            return scores / np.sum(scores)\n",
    "    \n",
    "        current = int(random.choice(graph[current]))\n",
    "        scores[current] += 1\n",
    "        \n",
    "    return scores / np.sum(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(filename, naive=False):\n",
    "    \"\"\" Utility function to print some information on a given graph.\n",
    "    \n",
    "        :param filename: name of the file containing the adjacency list\n",
    "        :param naive: whether to use the naive version of page_rank or not\n",
    "    \"\"\"\n",
    "    graph = file_to_directed_graph(filename)\n",
    "    nb_iterations = 50000\n",
    "\n",
    "    print(f\"The graph : {graph}\\n\")\n",
    "\n",
    "    for i in range(10):\n",
    "        if naive:\n",
    "            scores = page_rank_naive(graph, nb_iterations)\n",
    "        else:\n",
    "            scores = page_rank(graph, nb_iterations)\n",
    "        print(f\"trial {i} : {scores}\")\n",
    "        print(f\"\\tranking : {np.argsort(scores)}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph : {0: [1, 4], 1: [], 2: [3], 3: [0, 1, 2], 4: [1]}\n",
      "\n",
      "trial 0 : [0.33333333 0.33333333 0.         0.         0.33333333]\n",
      "\tranking : [2 3 0 1 4]\n",
      "\n",
      "\n",
      "trial 1 : [0.  0.2 0.4 0.4 0. ]\n",
      "\tranking : [0 4 1 2 3]\n",
      "\n",
      "\n",
      "trial 2 : [0.5 0.5 0.  0.  0. ]\n",
      "\tranking : [2 3 4 0 1]\n",
      "\n",
      "\n",
      "trial 3 : [0.5 0.5 0.  0.  0. ]\n",
      "\tranking : [2 3 4 0 1]\n",
      "\n",
      "\n",
      "trial 4 : [0.5 0.5 0.  0.  0. ]\n",
      "\tranking : [2 3 4 0 1]\n",
      "\n",
      "\n",
      "trial 5 : [0.33333333 0.33333333 0.         0.         0.33333333]\n",
      "\tranking : [2 3 0 1 4]\n",
      "\n",
      "\n",
      "trial 6 : [0.2 0.2 0.2 0.2 0.2]\n",
      "\tranking : [0 1 2 3 4]\n",
      "\n",
      "\n",
      "trial 7 : [0.14285714 0.14285714 0.28571429 0.28571429 0.14285714]\n",
      "\tranking : [0 1 4 2 3]\n",
      "\n",
      "\n",
      "trial 8 : [0. 1. 0. 0. 0.]\n",
      "\tranking : [0 2 3 4 1]\n",
      "\n",
      "\n",
      "trial 9 : [0.2 0.2 0.2 0.2 0.2]\n",
      "\tranking : [0 1 2 3 4]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(\"absorbing.graph\", naive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph presents an absorbing node in node 1, if the random walk starts there node 1 will have a maximum score.\n",
    "\n",
    "In general, we can see that the results are quite disparate from one trial to the other, because the presence of a dangling node comes down to having a variable number of iterations from one trial to the next, depending on how soon the random walk gets there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph : {0: [1], 1: [2, 3], 2: [0], 3: [2], 4: [5, 6], 5: [6], 6: [7], 7: [4]}\n",
      "\n",
      "trial 0 : [0.        0.        0.        0.        0.2850543 0.1448171 0.2850743\n",
      " 0.2850543]\n",
      "\tranking : [0 1 2 3 5 4 7 6]\n",
      "\n",
      "\n",
      "trial 1 : [0.28567429 0.28567429 0.28567429 0.14297714 0.         0.\n",
      " 0.         0.        ]\n",
      "\tranking : [4 5 6 7 3 0 1 2]\n",
      "\n",
      "\n",
      "trial 2 : [0.28559429 0.28559429 0.28557429 0.14323714 0.         0.\n",
      " 0.         0.        ]\n",
      "\tranking : [4 5 6 7 3 2 0 1]\n",
      "\n",
      "\n",
      "trial 3 : [0.         0.         0.         0.         0.28553429 0.14339713\n",
      " 0.28553429 0.28553429]\n",
      "\tranking : [0 1 2 3 5 4 6 7]\n",
      "\n",
      "\n",
      "trial 4 : [0.         0.         0.         0.         0.28575428 0.14275714\n",
      " 0.28575428 0.28573429]\n",
      "\tranking : [0 1 2 3 5 7 4 6]\n",
      "\n",
      "\n",
      "trial 5 : [0.         0.         0.         0.         0.28547429 0.14357713\n",
      " 0.28547429 0.28547429]\n",
      "\tranking : [0 1 2 3 5 4 6 7]\n",
      "\n",
      "\n",
      "trial 6 : [0.28551429 0.28551429 0.28551429 0.14345713 0.         0.\n",
      " 0.         0.        ]\n",
      "\tranking : [4 5 6 7 3 0 1 2]\n",
      "\n",
      "\n",
      "trial 7 : [0.         0.         0.         0.         0.28567429 0.14297714\n",
      " 0.28567429 0.28567429]\n",
      "\tranking : [0 1 2 3 5 4 6 7]\n",
      "\n",
      "\n",
      "trial 8 : [0.28623428 0.28621428 0.28621428 0.14133717 0.         0.\n",
      " 0.         0.        ]\n",
      "\tranking : [4 5 6 7 3 1 2 0]\n",
      "\n",
      "\n",
      "trial 9 : [0.         0.         0.         0.         0.2851943  0.14441711\n",
      " 0.2851943  0.2851943 ]\n",
      "\tranking : [0 1 2 3 5 4 6 7]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(\"components.graph\", naive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph presents two connected components, depending on where the random walk starts only one is explored. This can be observed in the above trials where there always is either the first or last four nodes with a score of 0.\n",
    "\n",
    "Apart from this, because there are no dangling nodes, the scores for each component are quite similar from one trial to the next when they are the one being explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(graph, nb_iterations, damping_factor=0.15):\n",
    "    \"\"\" Implementation of the page rank algorithm.\n",
    "        \n",
    "        :param graph: graph to explore, in the form of a dictionnary \n",
    "        with an array of adjacent nodes as the value asociated to each key\n",
    "        :param nb_iterations: the number of iterations the random walk is\n",
    "        going to try to take to explore the graph\n",
    "        :param damping_factor: the probability with which the random walk with just\n",
    "        start from a new random node\n",
    "        \n",
    "        :return: the score associated to each node, normalised, in the form of an array\n",
    "    \"\"\"\n",
    "    scores = np.zeros(len(graph))\n",
    "    current = random.choice(list(graph))\n",
    "    scores[current] += 1\n",
    "    \n",
    "    for i in range(nb_iterations):\n",
    "        if np.random.choice([True, False], p=[damping_factor, 1-damping_factor]):\n",
    "            current = random.choice(list(graph))\n",
    "        elif not graph[current]:\n",
    "            current = random.choice(list(graph))\n",
    "        else:\n",
    "            current = int(random.choice(graph[current]))\n",
    "        scores[current] += 1\n",
    "        \n",
    "    return scores / np.sum(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph : {0: [1, 4], 1: [], 2: [3], 3: [0, 1, 2], 4: [1]}\n",
      "\n",
      "trial 0 : [0.14803704 0.33809324 0.14873703 0.21355573 0.15157697]\n",
      "\tranking : [0 2 4 3 1]\n",
      "\n",
      "\n",
      "trial 1 : [0.14819704 0.33769325 0.15063699 0.21385572 0.14961701]\n",
      "\tranking : [0 4 2 3 1]\n",
      "\n",
      "\n",
      "trial 2 : [0.14749705 0.34057319 0.14641707 0.21133577 0.15417692]\n",
      "\tranking : [2 0 4 3 1]\n",
      "\n",
      "\n",
      "trial 3 : [0.14757705 0.34099318 0.14659707 0.21455571 0.15027699]\n",
      "\tranking : [2 0 4 3 1]\n",
      "\n",
      "\n",
      "trial 4 : [0.14753705 0.34257315 0.14709706 0.21253575 0.15025699]\n",
      "\tranking : [2 0 4 3 1]\n",
      "\n",
      "\n",
      "trial 5 : [0.14973701 0.33861323 0.14719706 0.21327573 0.15117698]\n",
      "\tranking : [2 0 4 3 1]\n",
      "\n",
      "\n",
      "trial 6 : [0.14603708 0.33871323 0.15089698 0.21645567 0.14789704]\n",
      "\tranking : [0 4 2 3 1]\n",
      "\n",
      "\n",
      "trial 7 : [0.14887702 0.33949321 0.14785704 0.21213576 0.15163697]\n",
      "\tranking : [2 0 4 3 1]\n",
      "\n",
      "\n",
      "trial 8 : [0.14765705 0.33701326 0.14927701 0.21277574 0.15327693]\n",
      "\tranking : [0 2 4 3 1]\n",
      "\n",
      "\n",
      "trial 9 : [0.14567709 0.3398732  0.14909702 0.21547569 0.149877  ]\n",
      "\tranking : [0 2 4 3 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(\"absorbing.graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new page rank implementation allows for much more consistent scores across trials, even if some disparities can still be observed in the final ranking. The effect of the dangling node is negated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph : {0: [1], 1: [2, 3], 2: [0], 3: [2], 4: [5, 6], 5: [6], 6: [7], 7: [4]}\n",
      "\n",
      "trial 0 : [0.13833723 0.13685726 0.14079718 0.0752385  0.14245715 0.07787844\n",
      " 0.1447771  0.14365713]\n",
      "\tranking : [3 5 1 0 2 4 7 6]\n",
      "\n",
      "\n",
      "trial 1 : [0.14285714 0.14097718 0.1447571  0.07835843 0.13453731 0.07717846\n",
      " 0.14221716 0.13911722]\n",
      "\tranking : [5 3 4 7 1 6 0 2]\n",
      "\n",
      "\n",
      "trial 2 : [0.1398972  0.13713726 0.14335713 0.07853843 0.13885722 0.07839843\n",
      " 0.14305714 0.14075718]\n",
      "\tranking : [5 3 1 4 0 7 6 2]\n",
      "\n",
      "\n",
      "trial 3 : [0.13853723 0.13615728 0.14097718 0.07685846 0.13971721 0.07781844\n",
      " 0.14613708 0.14379712]\n",
      "\tranking : [3 5 1 0 4 2 7 6]\n",
      "\n",
      "\n",
      "trial 4 : [0.1401172  0.13833723 0.14387712 0.07743845 0.13769725 0.07807844\n",
      " 0.14327713 0.14117718]\n",
      "\tranking : [3 5 4 1 0 7 6 2]\n",
      "\n",
      "\n",
      "trial 5 : [0.14473711 0.14157717 0.14769705 0.07889842 0.13385732 0.07677846\n",
      " 0.13969721 0.13675726]\n",
      "\tranking : [5 3 4 7 6 1 0 2]\n",
      "\n",
      "\n",
      "trial 6 : [0.14149717 0.13867723 0.14447711 0.07803844 0.13819724 0.07697846\n",
      " 0.14237715 0.1397572 ]\n",
      "\tranking : [5 3 4 1 7 0 6 2]\n",
      "\n",
      "\n",
      "trial 7 : [0.14105718 0.13763725 0.14345713 0.07799844 0.13895722 0.07719846\n",
      " 0.14305714 0.14063719]\n",
      "\tranking : [5 3 1 4 7 0 6 2]\n",
      "\n",
      "\n",
      "trial 8 : [0.13735725 0.13453731 0.14039719 0.07673847 0.14123718 0.07891842\n",
      " 0.14655707 0.14425711]\n",
      "\tranking : [3 5 1 0 2 4 7 6]\n",
      "\n",
      "\n",
      "trial 9 : [0.14225715 0.13951721 0.14617708 0.0801384  0.13643727 0.07601848\n",
      " 0.14149717 0.13795724]\n",
      "\tranking : [5 3 4 7 1 6 0 2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(\"components.graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new page rank implementation allows for the exploration of the totality of the graph, which negates the effect of the two separate connected components. Also, the scores are quite consistent even if as before the ranking can still vary a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_google_matrix(filename, theta=0.85):\n",
    "    \"\"\" Computation of the google matrix for the given graph.\n",
    "        \n",
    "        :param filename: name of the file containing the adjacency list\n",
    "        :param theta: probability of the random walk to stay on its current\n",
    "        path, 1 - theta is therefore the probability to start from a new random\n",
    "        node\n",
    "        \n",
    "        :return: google matrix in the form of an np.array\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"../data/\" + filename) as f:\n",
    "        content = f.read().splitlines()\n",
    "    \n",
    "    nb_nodes = len(content)\n",
    "    g = np.zeros((nb_nodes, nb_nodes))\n",
    "    \n",
    "    for line in content:\n",
    "        c = list(map(int, line.split()))\n",
    "        outgoing_degree = len(c) - 1\n",
    "        \n",
    "        if outgoing_degree == 0:\n",
    "            g[c[0]] = np.ones(nb_nodes) / nb_nodes\n",
    "        else:\n",
    "            for i in c[1:]:\n",
    "                g[c[0]][i] = 1 / outgoing_degree\n",
    "        \n",
    "    return theta * g + (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(g, nb_iterations=50):\n",
    "    \"\"\" Computation of the score of each node given a google matrix.\n",
    "        \n",
    "        :param g: google matrix\n",
    "        :param nb_iterations: number of iteration used to calculate \n",
    "        the score vector\n",
    "        \n",
    "        :return: the score vector\n",
    "    \"\"\"\n",
    "    \n",
    "    v = np.ones(np.shape(g)[0]) / np.shape(g)[0]\n",
    "\n",
    "    for i in range(nb_iterations):\n",
    "        v = v @ g\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_pages(id_array):\n",
    "    \"\"\" Utility function to get the title of Wikipedia pages given their index\n",
    "        \n",
    "        :param id_array: an array containing the indexes of the pages of which we\n",
    "        want the titles.\n",
    "        \n",
    "        :return: list of strings corresponding to the titles of the pages, given in\n",
    "        the same order as in id_array\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"../data/wikipedia_titles.tsv\") as f:\n",
    "        # Strip away the first line, because it corresponds to a legend and not to a page\n",
    "        content = np.array(f.read().splitlines()[1:])\n",
    "        \n",
    "    # Return the selected ids and format the result to only contain page titles (and not their id)\n",
    "    return list(map(lambda x: x.split(None, 1)[1], content[id_array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1 : United States\n",
      "rank 2 : United Kingdom\n",
      "rank 3 : France\n",
      "rank 4 : Europe\n",
      "rank 5 : Germany\n",
      "rank 6 : England\n",
      "rank 7 : World War II\n",
      "rank 8 : Latin\n",
      "rank 9 : India\n",
      "rank 10 : English language\n"
     ]
    }
   ],
   "source": [
    "filename = \"wikipedia.graph\"\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g)\n",
    "for i, t in enumerate(get_wikipedia_pages(np.argsort(scores)[-1:-11:-1])):\n",
    "    print(f\"rank {i + 1} : {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_and_rank_of_page(scores, page_id):\n",
    "    \"\"\" Utility function to get the score and rank of a Wikipedia page given its index\n",
    "        \n",
    "        :param scores: an array containing the scores of each pages\n",
    "        :param page_id: the id of the page of which we want the score and rank\n",
    "        \n",
    "        :return: formated string with the wnated information\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_of_pages = len(scores)\n",
    "    \n",
    "    page_title = get_wikipedia_pages([page_id])[0]\n",
    "    score = scores[page_id]\n",
    "    rank = np.nonzero(np.argsort(scores)[::-1] == page_id)[0][0]\n",
    "    \n",
    "    # Return a formated strings, with the rank going from 1 for the best to the number of pages for the worst\n",
    "    return f\"Page \\\"{page_title}\\\":\\n\\tScore: {score}\\n\\tRank: {rank + 1} out of {nb_of_pages}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page \"United States\":\n",
      "\tScore: 0.007459087286658105\n",
      "\tRank: 1 out of 5540\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 9.846341053223486e-05\n",
      "\tRank: 2530 out of 5540\n"
     ]
    }
   ],
   "source": [
    "filename = \"wikipedia.graph\"\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g)\n",
    "\n",
    "# ID of page \"United States\" as a check\n",
    "page_id = 5210\n",
    "print(get_score_and_rank_of_page(scores, page_id))\n",
    "\n",
    "# ID of page \"History of mathematics\"\n",
    "page_id = 2463\n",
    "print(get_score_and_rank_of_page(scores, page_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheating_google(g, scores, page_id, new_edge_budget, theta=0.85):\n",
    "    \"\"\" Alteration of the given google matrix by adding new edges to boost the\n",
    "        score of the given page.\n",
    "        One assumption made by this algorithm is that if for one node we have, \n",
    "        for every node, a non-zero probability to go there, then it is a dangling node. This\n",
    "        could be challenged by the fact that a page connected to every single page would have\n",
    "        the same effect on the google matrix as a dangling node, and therefore we would misclassify\n",
    "        those as dangling nodes. Because in real networks this never happens, we accept this assumption.\n",
    "        \n",
    "        :param g: google matrix to alter\n",
    "        :param scores: scores computed with the given google matrix\n",
    "        :param page_id: id of the page to boost\n",
    "        :param new_edge_budget: number of new edges we are allowed to add to the \n",
    "        graph to boost the score\n",
    "        :param theta: probability of the random walk to stay on its current\n",
    "        path, 1 - theta is therefore the probability to start from a new random\n",
    "        node, has to be the same as the one that was used to compute g in the first\n",
    "        place\n",
    "        \n",
    "        :return: an altered google matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_nodes = g.shape[0]\n",
    "    h_hat = g - (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes\n",
    "    ranking = np.argsort(scores)[::-1]\n",
    "    \n",
    "    # For every best ranked pages, add an edge from there to the page we want to boost\n",
    "    for i in range(new_edge_budget):\n",
    "        outgoing_degree = len(np.nonzero(h_hat[ranking[i]])[0])\n",
    "        \n",
    "        # If the page is a dangling node (i.e. in h_hat the page is connected to all pages)\n",
    "        if outgoing_degree == nb_nodes:\n",
    "            # Add an edge from this dangling node to the page_id\n",
    "            # i.e. the probabilty to go from this node to the selected one is 1, and to any other is 0\n",
    "            line = np.zeros(nb_nodes)\n",
    "            line[page_id] = 1\n",
    "            h_hat[ranking[i]] = line\n",
    "        else:\n",
    "            # If the page is not already connected to the page we want to boost, add an edge, otherwise skip this page\n",
    "            if h_hat[ranking[i]][page_id] == 0:\n",
    "                h_hat[ranking[i]] *= outgoing_degree / (outgoing_degree + 1)\n",
    "                h_hat[ranking[i]][page_id] += 1 / (outgoing_degree + 1)\n",
    "            else:\n",
    "                new_edge_budget += 1\n",
    "            \n",
    "    return h_hat + (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cheating :\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 9.846341053223486e-05\n",
      "\tRank: 2530 out of 5540\n",
      "\n",
      "\n",
      "After cheating (by adding 300 new edges):\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 0.005659430755510088\n",
      "\tRank: 2 out of 5540\n"
     ]
    }
   ],
   "source": [
    "# ID of page \"History of mathematics\"\n",
    "page_id = 2463\n",
    "new_edge_budget = 300\n",
    "filename = \"wikipedia.graph\"\n",
    "\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g, 50)\n",
    "print(\"Before cheating :\")\n",
    "print(get_score_and_rank_of_page(scores, page_id))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "g_cheat = cheating_google(g, scores, page_id, new_edge_budget)\n",
    "scores = power_iteration(g_cheat, 50)\n",
    "print(f\"After cheating (by adding {new_edge_budget} new edges):\")\n",
    "print(get_score_and_rank_of_page(scores, page_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
