{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *H*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *BAFFOU Jérémy*\n",
    "* *BASSETO Antoine*\n",
    "* *PINTO Andrea*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_directed_graph(filename):\n",
    "    \n",
    "    with open(\"../data/\" + filename) as f:\n",
    "        content = f.read().splitlines()\n",
    "    \n",
    "    graph = {}\n",
    "    for line in content:\n",
    "        c = list(map(int, line.split()))\n",
    "        graph[int(c[0])] = c[1:]\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank_naive(graph, nb_iterations):\n",
    "    scores = np.zeros(len(graph))\n",
    "    current = random.choice(list(graph))\n",
    "    scores[current] += 1\n",
    "    \n",
    "    for i in range(nb_iterations):\n",
    "        if not graph[current]:\n",
    "            return scores / np.sum(scores)\n",
    "    \n",
    "        current = int(random.choice(graph[current]))\n",
    "        scores[current] += 1\n",
    "        \n",
    "    return scores / np.sum(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 4], 1: [], 2: [3], 3: [0, 1, 2], 4: [1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.4, 0. ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"absorbing.graph\"\n",
    "graph = file_to_directed_graph(filename)\n",
    "print(graph)\n",
    "page_rank_naive(graph, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28571429, 0.28571429, 0.33333333, 0.0952381 , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"components.graph\"\n",
    "graph = file_to_directed_graph(filename)\n",
    "page_rank_naive(graph, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain result here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(graph, nb_iterations, damping_factor=0.15):\n",
    "    scores = np.zeros(len(graph))\n",
    "    current = random.choice(list(graph))\n",
    "    scores[current] += 1\n",
    "    \n",
    "    for i in range(nb_iterations):\n",
    "        if np.random.choice([True, False], p=[damping_factor, 1-damping_factor]):\n",
    "            current = random.choice(list(graph))\n",
    "        elif not graph[current]:\n",
    "            current = random.choice(list(graph))\n",
    "        else:\n",
    "            current = int(random.choice(graph[current]))\n",
    "        scores[current] += 1\n",
    "        \n",
    "    return scores / np.sum(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04761905, 0.19047619, 0.33333333, 0.38095238, 0.04761905])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"absorbing.graph\"\n",
    "graph = file_to_directed_graph(filename)\n",
    "page_rank(graph, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0952381 , 0.0952381 , 0.0952381 , 0.04761905, 0.19047619,\n",
       "       0.0952381 , 0.19047619, 0.19047619])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"components.graph\"\n",
    "graph = file_to_directed_graph(filename)\n",
    "page_rank(graph, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain result here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_google_matrix(filename, theta=0.85):\n",
    "    \n",
    "    with open(\"../data/\" + filename) as f:\n",
    "        content = f.read().splitlines()\n",
    "    \n",
    "    nb_nodes = len(content)\n",
    "    g = np.zeros((nb_nodes, nb_nodes))\n",
    "    \n",
    "    for line in content:\n",
    "        c = list(map(int, line.split()))\n",
    "        outgoing_degree = len(c) - 1\n",
    "        \n",
    "        if outgoing_degree == 0:\n",
    "            g[c[0]] = np.ones(nb_nodes) / nb_nodes\n",
    "        else:\n",
    "            for i in c[1:]:\n",
    "                g[c[0]][i] = 1 / outgoing_degree\n",
    "        \n",
    "    return theta * g + (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(g, nb_iterations):\n",
    "    v = np.ones(np.shape(g)[0]) / np.shape(g)[0]\n",
    "\n",
    "    for i in range(nb_iterations):\n",
    "        v = v @ g\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_pages(id_array):\n",
    "    \n",
    "    with open(\"../data/wikipedia_titles.tsv\") as f:\n",
    "        # Strip away the first line, because it corresponds to a legend and not to a page\n",
    "        content = np.array(f.read().splitlines()[1:])\n",
    "        \n",
    "    # Return the selected ids and format the result to only contain page titles (and not their id)\n",
    "    return list(map(lambda x: x.split(None, 1)[1], content[id_array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States',\n",
       " 'United Kingdom',\n",
       " 'France',\n",
       " 'Europe',\n",
       " 'Germany',\n",
       " 'England',\n",
       " 'World War II',\n",
       " 'Latin',\n",
       " 'India',\n",
       " 'English language']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"wikipedia.graph\"\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g, 50)\n",
    "get_wikipedia_pages(np.argsort(scores)[-1:-11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_and_rank_of_page(scores, page_id):\n",
    "    nb_of_pages = len(scores)\n",
    "    \n",
    "    page_title = get_wikipedia_pages([page_id])[0]\n",
    "    score = scores[page_id]\n",
    "    rank = np.nonzero(np.argsort(scores)[::-1] == page_id)[0][0]\n",
    "    \n",
    "    # Return a formated strings, with the rank going from 1 for the best to the number of pages for the worst\n",
    "    return f\"Page \\\"{page_title}\\\":\\n\\tScore: {score}\\n\\tRank: {rank + 1} out of {nb_of_pages}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page \"United States\":\n",
      "\tScore: 0.007459087286658076\n",
      "\tRank: 1 out of 5540\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 9.846341053223444e-05\n",
      "\tRank: 2530 out of 5540\n"
     ]
    }
   ],
   "source": [
    "filename = \"wikipedia.graph\"\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g, 50)\n",
    "\n",
    "# ID of page \"United States\" as a check\n",
    "page_id = 5210\n",
    "print(get_score_and_rank_of_page(scores, page_id))\n",
    "\n",
    "# ID of page \"History of mathematics\"\n",
    "page_id = 2463\n",
    "print(get_score_and_rank_of_page(scores, page_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheating_google(g, scores, page_id, new_edge_budget, theta=0.85):\n",
    "    nb_nodes = g.shape[0]\n",
    "    h_hat = g - (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes\n",
    "    ranking = np.argsort(scores)[::-1]\n",
    "    \n",
    "    for i in range(new_edge_budget):\n",
    "        outgoing_degree = len(np.nonzero(h_hat[ranking[i]])[0])\n",
    "        \n",
    "        # If the page is a dangling node (i.e. in h_hat the page is connected to all other pages)\n",
    "        # Does not work correctly if it is actually a page that links to every single other page, because it will consider those to be dangling nodes.\n",
    "        if outgoing_degree == nb_nodes:\n",
    "            line = np.zeros(nb_nodes)\n",
    "            line[page_id] = 1\n",
    "            h_hat[ranking[i]] = line\n",
    "        else:\n",
    "            h_hat[ranking[i]] *= outgoing_degree / (outgoing_degree + 1)\n",
    "            h_hat[ranking[i]][page_id] += 1 / (outgoing_degree + 1)\n",
    "            \n",
    "    return h_hat + (1 - theta) * np.ones((nb_nodes, nb_nodes)) / nb_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cheating :\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 9.846341053223444e-05\n",
      "\tRank: 2530 out of 5540\n",
      "\n",
      "\n",
      "After cheating (by adding 300 new edges):\n",
      "Page \"History of mathematics\":\n",
      "\tScore: 0.0057024291432487256\n",
      "\tRank: 2 out of 5540\n"
     ]
    }
   ],
   "source": [
    "# ID of page \"History of mathematics\"\n",
    "page_id = 2463\n",
    "new_edge_budget = 300\n",
    "filename = \"wikipedia.graph\"\n",
    "\n",
    "g = file_to_google_matrix(filename)\n",
    "scores = power_iteration(g, 50)\n",
    "print(\"Before cheating :\")\n",
    "print(get_score_and_rank_of_page(scores, page_id))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "g_cheat = cheating_google(g, scores, page_id, new_edge_budget)\n",
    "scores = power_iteration(g_cheat, 50)\n",
    "print(f\"After cheating (by adding {new_edge_budget} new edges):\")\n",
    "print(get_score_and_rank_of_page(scores, page_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
