{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *H*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Baffou Jérémy*\n",
    "* *Basseto Antoine*\n",
    "* *Pinto Andrea*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = np.load(\"tf_idf.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"term_mapping.pkl\", \"rb\")\n",
    "term_mapping = pickle.load(a_file)\n",
    "b_file = open(\"doc_mapping.pkl\", \"rb\")\n",
    "doc_mapping = pickle.load(b_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,v_T = svds(tf_idf,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of $U$ give \"eigenvectors\" of the correlation matrix row-wise of the TF-IDF matrix (so based on words), ordered in decreasing order of variance they capture. The columns of $V^T$, i.e. rows of $V$, are the \"eigenvectors\" of the correlation matrix column-wise of the TF_IDF matrix (so based on documents), ordered in decreasing order of variance they capture. The value of S are the singular values of the TF-IDF matrix, which indicate how much an association of vectors of U and V are necessary to give back original vectors of TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.09873700362627\n",
      "169.64304845125847\n",
      "165.13623644729898\n",
      "136.25088829659356\n",
      "101.7752297755353\n",
      "101.76363764441108\n",
      "89.43790812020335\n",
      "88.15683571820087\n",
      "84.95820920506627\n",
      "83.02381499774205\n",
      "81.01756621101589\n",
      "80.56113321488992\n",
      "79.45357279531936\n",
      "77.92684554601456\n",
      "76.6961681839419\n",
      "76.41374279372636\n",
      "76.07771993649644\n",
      "76.00869823265448\n",
      "73.95950505191009\n",
      "69.07977395905486\n"
     ]
    }
   ],
   "source": [
    "for singular_value in sorted(s[-20:],key=lambda l : -l):\n",
    "    print(singular_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_extract(index):\n",
    "    term_indexes = u[:,index].argsort()[-10:][::-1]\n",
    "    terms_keys = list(term_mapping.keys())\n",
    "    for j in term_indexes:\n",
    "        print(terms_keys[j])\n",
    "    print(\"-----------------------\")\n",
    "    doc_indexes = v_T[:,index].argsort()[-10:][::-1]\n",
    "    doc_keys = list(doc_mapping.keys())\n",
    "    for k in doc_indexes:\n",
    "        print(doc_keys[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase equilibrium thermodynamics\n",
      "equilibriumstage approach\n",
      "equilibrium thermodynamics\n",
      "equilibriumstage\n",
      "gas absorption\n",
      "separation process\n",
      "performance separation\n",
      "estimate mass transfer\n",
      "take mass\n",
      "take mass transfer\n",
      "-----------------------\n",
      "ME-444\n",
      "BIO-622\n",
      "COM-407\n",
      "ENV-405\n",
      "MSE-653\n",
      "MICRO-614\n",
      "CH-423\n",
      "BIO-483\n",
      "MATH-350\n",
      "BIO-692\n"
     ]
    }
   ],
   "source": [
    "topic_extract(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
